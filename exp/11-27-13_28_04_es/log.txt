2023-11-27 13:28:04,234 - __main__ - INFO - start logging : {"fname": "./exp/11-27-13_28_04/log.txt", "level": "INFO", "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"}
2023-11-27 13:28:04,234 - __main__ - INFO - info: {"name": "DynRT", "log": {"name": ""}, "device": [0], "test_on_checkpoint": "none", "train_on_checkpoint": "none"}
2023-11-27 13:28:04,237 - __main__ - INFO - Set Seed : 2
2023-11-27 13:28:04,237 - __main__ - INFO - Require : ['tokenizer_roberta']
2023-11-27 13:28:05,388 - __main__ - INFO - Loaded tokenizer_roberta : {"path": "xlm-roberta-base"}
2023-11-27 13:28:07,337 - __main__ - INFO - Prepared text : {"data_path": "input_es/prepared_clean/", "len": 100, "pad": 1}
2023-11-27 13:28:07,353 - __main__ - INFO - Prepared img : {"data_path": "input_es/prepared_clean/", "transform_image": "image_tensor/"}
2023-11-27 13:28:07,358 - __main__ - INFO - Prepared label : {"data_path": "input_es/prepared_clean/", "test_label": true}
2023-11-27 13:28:07,359 - __main__ - INFO - Created DataLoaders : {"batch_size": 32, "pin_memory": true, "num_workers": 0, "shuffle": true}
2023-11-27 13:28:12,453 - __main__ - INFO - load model none
2023-11-27 13:28:12,453 - __main__ - INFO - Created Model : {"name": "DynRT", "input1": "text", "input2": "img", "input3": "text_mask", "layer": 4, "tau_max": 10, "ORDERS": [0, 1, 2, 3], "IMG_SCALE": 7, "dropout": 0.3, "hidden_size": 768, "ffn_size": 768, "multihead": 2, "routing": "hard", "BINARIZE": false, "len": 100, "glimpses": 1, "mlp_size": 768, "output_size": 768, "orders": 4, "pooling": "avg", "classifier": "both", "roberta_path": "xlm-roberta-base", "roberta_layer": 1, "vitmodel": "vit_base_patch32_224", "finetune": false}
2023-11-27 13:28:12,453 - __main__ - INFO - Created Optimizer : {"name": "Adam", "lr": 5e-06, "weight_decay": 0.01, "params": {"bertl_text": {"lr": 5e-06}, "vit": {"lr": 5e-06, "weight_decay": 0.01}, "trar": {"lr": 1e-06, "weight_decay": 0.01}, "classifier": {}}}
2023-11-27 13:28:12,453 - __main__ - INFO - Created Loss : {"name": "CrossEntropyLoss"}
2023-11-27 13:28:12,935 - __main__ - INFO - Model To Device : cuda:0
2023-11-27 13:28:12,936 - __main__ - INFO - loss To Device : cuda:0
2023-11-27 13:28:12,937 - __main__ - INFO - Clip: 10
2023-11-27 13:28:12,937 - __main__ - INFO - Epoch 1/15
2023-11-27 13:33:57,811 - __main__ - INFO - [[9563 1605]
 [5707 2677]]
2023-11-27 13:33:57,811 - __main__ - INFO - train : F1: 0.5731, Precision: 0.6257, Recall : 0.5878, Accuracy: 0.6260, Loss: 0.6549.
2023-11-27 13:34:18,178 - __main__ - INFO - [[1178  272]
 [ 515  422]]
2023-11-27 13:34:18,178 - __main__ - INFO - valid: F1: 0.5175, Precision: 0.6081, Recall : 0.4504, Accuracy: 0.6703, Loss: 0.6239.
2023-11-27 13:34:18,188 - __main__ - INFO - valid-macro: F1: 0.6335, Precision: 0.6519, Recall : 0.6314.
2023-11-27 13:34:18,188 - __main__ - INFO - save best model for now, epoch:1
2023-11-27 13:34:40,143 - __main__ - INFO - [[1184  264]
 [ 490  435]]
2023-11-27 13:34:40,146 - __main__ - INFO - test: F1: 0.5357, Precision: 0.6223, Recall : 0.4703, Accuracy: 0.6823, Loss: 0.6135.
2023-11-27 13:34:40,146 - __main__ - INFO - test-macro: F1: 0.6471, Precision: 0.6648, Recall : 0.6440.
2023-11-27 13:34:40,146 - __main__ - INFO - Epoch 2/15
2023-11-27 13:40:25,670 - __main__ - INFO - [[8772 2398]
 [3635 4747]]
2023-11-27 13:40:25,670 - __main__ - INFO - train : F1: 0.6778, Precision: 0.6857, Recall : 0.6758, Accuracy: 0.6914, Loss: 0.6143.
2023-11-27 13:40:46,061 - __main__ - INFO - [[1094  356]
 [ 429  508]]
2023-11-27 13:40:46,061 - __main__ - INFO - valid: F1: 0.5641, Precision: 0.5880, Recall : 0.5422, Accuracy: 0.6711, Loss: 0.6128.
2023-11-27 13:40:46,061 - __main__ - INFO - valid-macro: F1: 0.6500, Precision: 0.6531, Recall : 0.6483.
2023-11-27 13:40:46,061 - __main__ - INFO - save best model for now, epoch:2
2023-11-27 13:41:08,865 - __main__ - INFO - [[1095  353]
 [ 391  534]]
2023-11-27 13:41:08,869 - __main__ - INFO - test: F1: 0.5894, Precision: 0.6020, Recall : 0.5773, Accuracy: 0.6865, Loss: 0.5990.
2023-11-27 13:41:08,869 - __main__ - INFO - test-macro: F1: 0.6679, Precision: 0.6695, Recall : 0.6668.
2023-11-27 13:41:08,872 - __main__ - INFO - Epoch 3/15
2023-11-27 13:46:49,990 - __main__ - INFO - [[8493 2676]
 [3207 5176]]
2023-11-27 13:46:49,991 - __main__ - INFO - train : F1: 0.6902, Precision: 0.6925, Recall : 0.6889, Accuracy: 0.6991, Loss: 0.6010.
2023-11-27 13:47:10,127 - __main__ - INFO - [[1086  364]
 [ 413  524]]
2023-11-27 13:47:10,127 - __main__ - INFO - valid: F1: 0.5742, Precision: 0.5901, Recall : 0.5592, Accuracy: 0.6745, Loss: 0.6071.
2023-11-27 13:47:10,128 - __main__ - INFO - valid-macro: F1: 0.6554, Precision: 0.6573, Recall : 0.6541.
2023-11-27 13:47:10,128 - __main__ - INFO - save best model for now, epoch:3
2023-11-27 13:47:31,962 - __main__ - INFO - [[1089  359]
 [ 374  551]]
2023-11-27 13:47:31,967 - __main__ - INFO - test: F1: 0.6005, Precision: 0.6055, Recall : 0.5957, Accuracy: 0.6911, Loss: 0.5924.
2023-11-27 13:47:31,967 - __main__ - INFO - test-macro: F1: 0.6744, Precision: 0.6749, Recall : 0.6739.
2023-11-27 13:47:31,969 - __main__ - INFO - Epoch 4/15
2023-11-27 13:53:10,837 - __main__ - INFO - [[8424 2745]
 [3014 5369]]
2023-11-27 13:53:10,838 - __main__ - INFO - train : F1: 0.6981, Precision: 0.6991, Recall : 0.6973, Accuracy: 0.7055, Loss: 0.5942.
2023-11-27 13:53:31,123 - __main__ - INFO - [[1077  373]
 [ 391  546]]
2023-11-27 13:53:31,124 - __main__ - INFO - valid: F1: 0.5884, Precision: 0.5941, Recall : 0.5827, Accuracy: 0.6799, Loss: 0.6036.
2023-11-27 13:53:31,125 - __main__ - INFO - valid-macro: F1: 0.6633, Precision: 0.6639, Recall : 0.6627.
2023-11-27 13:53:31,125 - __main__ - INFO - save best model for now, epoch:4
2023-11-27 13:53:52,703 - __main__ - INFO - [[1085  363]
 [ 347  578]]
2023-11-27 13:53:52,708 - __main__ - INFO - test: F1: 0.6195, Precision: 0.6142, Recall : 0.6249, Accuracy: 0.7008, Loss: 0.5885.
2023-11-27 13:53:52,709 - __main__ - INFO - test-macro: F1: 0.6865, Precision: 0.6860, Recall : 0.6871.
2023-11-27 13:53:52,710 - __main__ - INFO - Epoch 5/15
2023-11-27 13:59:33,308 - __main__ - INFO - [[8503 2666]
 [2994 5389]]
2023-11-27 13:59:33,308 - __main__ - INFO - train : F1: 0.7030, Precision: 0.7043, Recall : 0.7021, Accuracy: 0.7105, Loss: 0.5893.
2023-11-27 13:59:55,319 - __main__ - INFO - [[1039  411]
 [ 341  596]]
2023-11-27 13:59:55,319 - __main__ - INFO - valid: F1: 0.6132, Precision: 0.5919, Recall : 0.6361, Accuracy: 0.6850, Loss: 0.6028.
2023-11-27 13:59:55,319 - __main__ - INFO - valid-macro: F1: 0.6737, Precision: 0.6724, Recall : 0.6763.
2023-11-27 13:59:55,319 - __main__ - INFO - save best model for now, epoch:5
2023-11-27 14:00:21,007 - __main__ - INFO - [[1048  400]
 [ 307  618]]
2023-11-27 14:00:21,016 - __main__ - INFO - test: F1: 0.6361, Precision: 0.6071, Recall : 0.6681, Accuracy: 0.7021, Loss: 0.5870.
2023-11-27 14:00:21,016 - __main__ - INFO - test-macro: F1: 0.6919, Precision: 0.6903, Recall : 0.6959.
2023-11-27 14:00:21,016 - __main__ - INFO - Epoch 6/15
2023-11-27 14:06:05,708 - __main__ - INFO - [[8408 2762]
 [2825 5557]]
2023-11-27 14:06:05,710 - __main__ - INFO - train : F1: 0.7080, Precision: 0.7082, Recall : 0.7078, Accuracy: 0.7142, Loss: 0.5852.
2023-11-27 14:06:25,957 - __main__ - INFO - [[1083  367]
 [ 357  580]]
2023-11-27 14:06:25,958 - __main__ - INFO - valid: F1: 0.6157, Precision: 0.6125, Recall : 0.6190, Accuracy: 0.6967, Loss: 0.5967.
2023-11-27 14:06:25,958 - __main__ - INFO - valid-macro: F1: 0.6826, Precision: 0.6823, Recall : 0.6829.
2023-11-27 14:06:25,959 - __main__ - INFO - save best model for now, epoch:6
2023-11-27 14:06:48,149 - __main__ - INFO - [[1077  371]
 [ 326  599]]
2023-11-27 14:06:48,152 - __main__ - INFO - test: F1: 0.6322, Precision: 0.6175, Recall : 0.6476, Accuracy: 0.7063, Loss: 0.5819.
2023-11-27 14:06:48,153 - __main__ - INFO - test-macro: F1: 0.6939, Precision: 0.6926, Recall : 0.6957.
2023-11-27 14:06:48,154 - __main__ - INFO - Epoch 7/15
2023-11-27 14:12:29,278 - __main__ - INFO - [[8476 2693]
 [2840 5543]]
2023-11-27 14:12:29,279 - __main__ - INFO - train : F1: 0.7105, Precision: 0.7110, Recall : 0.7101, Accuracy: 0.7170, Loss: 0.5811.
2023-11-27 14:12:49,351 - __main__ - INFO - [[1064  386]
 [ 329  608]]
2023-11-27 14:12:49,351 - __main__ - INFO - valid: F1: 0.6297, Precision: 0.6117, Recall : 0.6489, Accuracy: 0.7005, Loss: 0.5943.
2023-11-27 14:12:49,352 - __main__ - INFO - valid-macro: F1: 0.6891, Precision: 0.6877, Recall : 0.6913.
2023-11-27 14:12:49,352 - __main__ - INFO - save best model for now, epoch:7
2023-11-27 14:13:11,135 - __main__ - INFO - [[1057  391]
 [ 304  621]]
2023-11-27 14:13:11,138 - __main__ - INFO - test: F1: 0.6412, Precision: 0.6136, Recall : 0.6714, Accuracy: 0.7071, Loss: 0.5796.
2023-11-27 14:13:11,139 - __main__ - INFO - test-macro: F1: 0.6969, Precision: 0.6951, Recall : 0.7007.
2023-11-27 14:13:11,141 - __main__ - INFO - Epoch 8/15
2023-11-27 14:18:50,311 - __main__ - INFO - [[8463 2706]
 [2725 5658]]
2023-11-27 14:18:50,311 - __main__ - INFO - train : F1: 0.7164, Precision: 0.7165, Recall : 0.7163, Accuracy: 0.7222, Loss: 0.5776.
2023-11-27 14:19:10,487 - __main__ - INFO - [[1085  365]
 [ 336  601]]
2023-11-27 14:19:10,487 - __main__ - INFO - valid: F1: 0.6316, Precision: 0.6222, Recall : 0.6414, Accuracy: 0.7063, Loss: 0.5898.
2023-11-27 14:19:10,487 - __main__ - INFO - valid-macro: F1: 0.6937, Precision: 0.6929, Recall : 0.6948.
2023-11-27 14:19:10,487 - __main__ - INFO - save best model for now, epoch:8
2023-11-27 14:19:32,546 - __main__ - INFO - [[1072  376]
 [ 315  610]]
2023-11-27 14:19:32,559 - __main__ - INFO - test: F1: 0.6384, Precision: 0.6187, Recall : 0.6595, Accuracy: 0.7088, Loss: 0.5755.
2023-11-27 14:19:32,559 - __main__ - INFO - test-macro: F1: 0.6973, Precision: 0.6958, Recall : 0.6999.
2023-11-27 14:19:32,561 - __main__ - INFO - Epoch 9/15
2023-11-27 14:25:14,743 - __main__ - INFO - [[8564 2605]
 [2738 5645]]
2023-11-27 14:25:14,743 - __main__ - INFO - train : F1: 0.7205, Precision: 0.7210, Recall : 0.7201, Accuracy: 0.7267, Loss: 0.5737.
2023-11-27 14:25:34,850 - __main__ - INFO - [[1079  371]
 [ 322  615]]
2023-11-27 14:25:34,860 - __main__ - INFO - valid: F1: 0.6396, Precision: 0.6237, Recall : 0.6564, Accuracy: 0.7097, Loss: 0.5865.
2023-11-27 14:25:34,860 - __main__ - INFO - valid-macro: F1: 0.6983, Precision: 0.6969, Recall : 0.7002.
2023-11-27 14:25:34,860 - __main__ - INFO - save best model for now, epoch:9
2023-11-27 14:25:56,685 - __main__ - INFO - [[1071  377]
 [ 302  623]]
2023-11-27 14:25:56,689 - __main__ - INFO - test: F1: 0.6473, Precision: 0.6230, Recall : 0.6735, Accuracy: 0.7139, Loss: 0.5724.
2023-11-27 14:25:56,689 - __main__ - INFO - test-macro: F1: 0.7033, Precision: 0.7015, Recall : 0.7066.
2023-11-27 14:25:56,691 - __main__ - INFO - Epoch 10/15
2023-11-27 14:31:38,063 - __main__ - INFO - [[8583 2587]
 [2670 5712]]
2023-11-27 14:31:38,065 - __main__ - INFO - train : F1: 0.7252, Precision: 0.7255, Recall : 0.7249, Accuracy: 0.7311, Loss: 0.5700.
2023-11-27 14:31:58,367 - __main__ - INFO - [[1087  363]
 [ 315  622]]
2023-11-27 14:31:58,367 - __main__ - INFO - valid: F1: 0.6472, Precision: 0.6315, Recall : 0.6638, Accuracy: 0.7160, Loss: 0.5822.
2023-11-27 14:31:58,367 - __main__ - INFO - valid-macro: F1: 0.7048, Precision: 0.7034, Recall : 0.7067.
2023-11-27 14:31:58,367 - __main__ - INFO - save best model for now, epoch:10
2023-11-27 14:32:20,195 - __main__ - INFO - [[1083  365]
 [ 300  625]]
2023-11-27 14:32:20,199 - __main__ - INFO - test: F1: 0.6527, Precision: 0.6313, Recall : 0.6757, Accuracy: 0.7198, Loss: 0.5686.
2023-11-27 14:32:20,199 - __main__ - INFO - test-macro: F1: 0.7089, Precision: 0.7072, Recall : 0.7118.
2023-11-27 14:32:20,201 - __main__ - INFO - Epoch 11/15
2023-11-27 14:38:01,616 - __main__ - INFO - [[8687 2483]
 [2635 5747]]
2023-11-27 14:38:01,626 - __main__ - INFO - train : F1: 0.7322, Precision: 0.7328, Recall : 0.7317, Accuracy: 0.7382, Loss: 0.5653.
2023-11-27 14:38:21,976 - __main__ - INFO - [[1067  383]
 [ 305  632]]
2023-11-27 14:38:21,976 - __main__ - INFO - valid: F1: 0.6475, Precision: 0.6227, Recall : 0.6745, Accuracy: 0.7118, Loss: 0.5799.
2023-11-27 14:38:21,976 - __main__ - INFO - valid-macro: F1: 0.7019, Precision: 0.7002, Recall : 0.7052.
2023-11-27 14:38:21,976 - __main__ - INFO - save best model for now, epoch:11
2023-11-27 14:38:43,955 - __main__ - INFO - [[1063  385]
 [ 277  648]]
2023-11-27 14:38:43,956 - __main__ - INFO - test: F1: 0.6619, Precision: 0.6273, Recall : 0.7005, Accuracy: 0.7210, Loss: 0.5663.
2023-11-27 14:38:43,956 - __main__ - INFO - test-macro: F1: 0.7122, Precision: 0.7103, Recall : 0.7173.
2023-11-27 14:38:43,960 - __main__ - INFO - Epoch 12/15
2023-11-27 14:44:25,944 - __main__ - INFO - [[8714 2456]
 [2586 5796]]
2023-11-27 14:44:25,954 - __main__ - INFO - train : F1: 0.7362, Precision: 0.7368, Recall : 0.7358, Accuracy: 0.7421, Loss: 0.5615.
2023-11-27 14:44:46,217 - __main__ - INFO - [[1096  354]
 [ 309  628]]
2023-11-27 14:44:46,217 - __main__ - INFO - valid: F1: 0.6545, Precision: 0.6395, Recall : 0.6702, Accuracy: 0.7222, Loss: 0.5739.
2023-11-27 14:44:46,217 - __main__ - INFO - valid-macro: F1: 0.7111, Precision: 0.7098, Recall : 0.7130.
2023-11-27 14:44:46,217 - __main__ - INFO - save best model for now, epoch:12
2023-11-27 14:45:08,178 - __main__ - INFO - [[1088  360]
 [ 291  634]]
2023-11-27 14:45:08,189 - __main__ - INFO - test: F1: 0.6608, Precision: 0.6378, Recall : 0.6854, Accuracy: 0.7257, Loss: 0.5614.
2023-11-27 14:45:08,189 - __main__ - INFO - test-macro: F1: 0.7152, Precision: 0.7134, Recall : 0.7184.
2023-11-27 14:45:08,189 - __main__ - INFO - Epoch 13/15
2023-11-27 14:50:50,203 - __main__ - INFO - [[8856 2313]
 [2587 5796]]
2023-11-27 14:50:50,203 - __main__ - INFO - train : F1: 0.7431, Precision: 0.7443, Recall : 0.7422, Accuracy: 0.7494, Loss: 0.5565.
2023-11-27 14:51:10,438 - __main__ - INFO - [[1107  343]
 [ 304  633]]
2023-11-27 14:51:10,439 - __main__ - INFO - valid: F1: 0.6618, Precision: 0.6486, Recall : 0.6756, Accuracy: 0.7289, Loss: 0.5691.
2023-11-27 14:51:10,439 - __main__ - INFO - valid-macro: F1: 0.7178, Precision: 0.7166, Recall : 0.7195.
2023-11-27 14:51:10,439 - __main__ - INFO - save best model for now, epoch:13
2023-11-27 14:51:32,129 - __main__ - INFO - [[1103  345]
 [ 289  636]]
2023-11-27 14:51:32,133 - __main__ - INFO - test: F1: 0.6674, Precision: 0.6483, Recall : 0.6876, Accuracy: 0.7328, Loss: 0.5571.
2023-11-27 14:51:32,133 - __main__ - INFO - test-macro: F1: 0.7221, Precision: 0.7204, Recall : 0.7247.
2023-11-27 14:51:32,134 - __main__ - INFO - Epoch 14/15
2023-11-27 14:57:14,064 - __main__ - INFO - [[8913 2256]
 [2567 5816]]
2023-11-27 14:57:14,065 - __main__ - INFO - train : F1: 0.7470, Precision: 0.7485, Recall : 0.7459, Accuracy: 0.7533, Loss: 0.5513.
2023-11-27 14:57:34,351 - __main__ - INFO - [[1066  384]
 [ 267  670]]
2023-11-27 14:57:34,352 - __main__ - INFO - valid: F1: 0.6730, Precision: 0.6357, Recall : 0.7150, Accuracy: 0.7273, Loss: 0.5693.
2023-11-27 14:57:34,352 - __main__ - INFO - valid-macro: F1: 0.7196, Precision: 0.7177, Recall : 0.7251.
2023-11-27 14:57:34,352 - __main__ - INFO - save best model for now, epoch:14
2023-11-27 14:57:56,061 - __main__ - INFO - [[1056  392]
 [ 240  685]]
2023-11-27 14:57:56,065 - __main__ - INFO - test: F1: 0.6843, Precision: 0.6360, Recall : 0.7405, Accuracy: 0.7337, Loss: 0.5580.
2023-11-27 14:57:56,065 - __main__ - INFO - test-macro: F1: 0.7270, Precision: 0.7254, Recall : 0.7349.
2023-11-27 14:57:56,067 - __main__ - INFO - Epoch 15/15
2023-11-27 15:03:38,427 - __main__ - INFO - [[8993 2176]
 [2545 5838]]
2023-11-27 15:03:38,428 - __main__ - INFO - train : F1: 0.7521, Precision: 0.7539, Recall : 0.7508, Accuracy: 0.7585, Loss: 0.5461.
2023-11-27 15:03:58,871 - __main__ - INFO - [[1083  367]
 [ 280  657]]
2023-11-27 15:03:58,872 - __main__ - INFO - valid: F1: 0.6701, Precision: 0.6416, Recall : 0.7012, Accuracy: 0.7289, Loss: 0.5625.
2023-11-27 15:03:58,873 - __main__ - INFO - valid-macro: F1: 0.7200, Precision: 0.7181, Recall : 0.7240.
2023-11-27 15:04:18,731 - __main__ - INFO - [[1081  367]
 [ 266  659]]
2023-11-27 15:04:18,737 - __main__ - INFO - test: F1: 0.6756, Precision: 0.6423, Recall : 0.7124, Accuracy: 0.7332, Loss: 0.5527.
2023-11-27 15:04:18,737 - __main__ - INFO - test-macro: F1: 0.7245, Precision: 0.7224, Recall : 0.7295.
2023-11-27 15:18:44,450 - __main__ - INFO - start logging : {"fname": "./exp/11-27-13_28_04_es/log.txt", "level": "INFO", "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"}
2023-11-27 15:18:44,453 - __main__ - INFO - info: {"name": "DynRT", "log": {"name": ""}, "device": [0], "test_on_checkpoint": "exp/11-27-13_28_04_es/checkpoints/model_best.pth.tar", "train_on_checkpoint": "none"}
2023-11-27 15:18:44,453 - __main__ - INFO - Require : ['tokenizer_roberta']
2023-11-27 15:18:45,757 - __main__ - INFO - Loaded tokenizer_roberta : {"path": "xlm-roberta-base/"}
2023-11-27 15:18:47,777 - __main__ - INFO - Prepared text : {"data_path": "input_es/prepared_clean/", "len": 100, "pad": 1}
2023-11-27 15:18:47,785 - __main__ - INFO - Prepared img : {"data_path": "input_es/prepared_clean/", "transform_image": "image_tensor/"}
2023-11-27 15:18:47,786 - __main__ - INFO - Prepared label : {"data_path": "input_es/prepared_clean/", "test_label": true}
2023-11-27 15:18:47,787 - __main__ - INFO - Created DataLoaders : {"batch_size": 32, "pin_memory": true, "num_workers": 0, "shuffle": true, "drop_last": true}
2023-11-27 15:19:05,961 - __main__ - INFO - load model exp/11-27-13_28_04_es/checkpoints/model_best.pth.tar
2023-11-27 15:19:05,961 - __main__ - INFO - Created Model : {"name": "DynRT", "input1": "text", "input2": "img", "input3": "text_mask", "layer": 4, "tau_max": 10, "ORDERS": [0, 1, 2, 3], "IMG_SCALE": 7, "dropout": 0.5, "hidden_size": 768, "ffn_size": 768, "multihead": 2, "routing": "hard", "BINARIZE": false, "len": 100, "glimpses": 1, "mlp_size": 768, "output_size": 768, "orders": 4, "pooling": "avg", "classifier": "both", "roberta_path": "xlm-roberta-base/", "roberta_layer": 1, "vitmodel": "vit_base_patch32_224", "finetune": false}
2023-11-27 15:19:06,229 - __main__ - INFO - Model To Device : cuda:0
2023-11-27 15:19:06,229 - __main__ - INFO - loss To Device : cuda:0
2023-11-27 15:19:39,206 - __main__ - INFO - [[1055  393]
 [ 241  684]]
2023-11-27 15:19:39,209 - __main__ - INFO - test: F1: 0.6833, Precision: 0.6351, Recall : 0.7395, Accuracy: 0.7328, Loss: 0.5580.
